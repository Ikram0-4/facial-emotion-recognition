# facial-emotion-recognition
Détection des émotions faciales à partir d’images en utilisant le dataset FER2013 et un modèle CNN ou ResNet18. Application à l’adaptation d’interface utilisateur selon l’émotion détectée.


Ce projet a pour objectif de reconnaître les émotions humaines à partir du visage, en utilisant des techniques de vision par ordinateur et de deep learning. Il s’appuie sur le dataset FER2013 pour entraîner un modèle de classification (CNN ou ResNet18) capable d’identifier des émotions telles que la joie, la tristesse, la colère, etc.

Technologies utilisées :
Python

OpenCV pour la détection faciale

PyTorch pour l’entraînement du modèle (CNN / ResNet18)

FER2013 comme base de données d'entraînement

Cas d’usage :
Interfaces utilisateurs adaptatives (UI qui change selon l’émotion)

Outils pour les enseignants en ligne (suivi émotionnel des élèves)

Applications RH (analyse émotionnelle lors d’entretiens à distance)

Ce projet est destiné à illustrer l’application concrète de l’intelligence artificielle dans le domaine de la perception humaine.
